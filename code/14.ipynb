{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0da041fd-b2fa-4d76-883f-2013e7ba20cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # 应返回True\n",
    "print(torch.cuda.get_device_name(0))  # 显示GPU型号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5360f0-27fc-45b4-a421-87e63a653317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大家好今天是2025年的3月12号星期三讲卢奇兰凯恩斯就业利息货币通论第六奖第六奖讲的是通论里边第三章这是正常进入了他是从里面挑着讲他顺序也不是按正常通论的顺序去讲然后他会把他其中像这个是第三章他下一讲应该把13章14章的凑在一起了是按照这样讲的就是说他有他的这么一个顺序这方面你理解因为说实话像资本论和通论这种东西不好理解大不同你自己去读的话你可能读不到什么好不好我们这种讲法是你才能真的理解他为什么这么写目的是什么好吧我们来看拿日本举例1985年广场协议的核心点就是要求日元的升息这章主要讲的就是有效需求我们来看看日元升值日元升值之后涉及到什么就是说货币的问题就是货币升值的日元升级升值之后导致日本货币总量的膨胀什么概念就是日元的数量并没有增加他不是说多发了货币但是由于升值了之后日元的购买力增强了升值之后日元购买力增强怪得到迅速的膨胀所以货币总量的膨胀是导致总需求的增长你明白吗就是说我买能够更多那么我的需求就更多那么就成为了一个就是说货币总量的膨胀是总需求增长的一个根本性的原因好在这的时候你要理解他这是通过货币升值导致的我还可以通过多发货币导致你知道吗那么回来下一章可能就会讲到了就是说那么我们如果时不时的多发一点货币的话实际上就能够提高总需求提高经济发展所以为什么你看基本上经济学家都保障每年有2%的通货膨胀你明白这意思吗就有在这然后再每年根据你的GDP在相应的开始多发一点货币好那么当然总需求和有效需求是两码事总需求攀升之后大量的货币变成了两个东西一个就是投资性的需求因为挣的钱是投资另外一个就消费性的需求挣的钱到哪去消费投资性需求导致日本的房地产和股市起飞整个就封掉封掉之后由于货币量太大了日本放不下就进行大规模的海外投资主要进入美国当时觉得把东京房地产都卖掉就可以把整个美国都买下来了还记得吧到美国买什么的个大差什么的这个实质上本质是一个资本外逃的过程你懂明白吗同时又有大量的消费性需求消费性需求提高之后日本本国无法满足满足之后就要从国外进口当时的日本比如说买LV包当时LV会专门给日本出日本特供的一些包的款式颜色都会有你现在你包括你看爱比我记得去年的时候就给日本出了一个专门的一个日本配色的一个蓝宝石的爱比的双飞轮很好看的表也是日本特供对不对那么就都会有因为当时日本挣钱买的东西多这些奢侈品就专门给他提供很多东西日本国内无法满足的这种需求那么就需要外部性的消费需求那么外部性的投资和这种消费需求会导致什么导致日本大量资本外溢你知道吗因为人家爱比也好人家LV来了挣了钱之后人家要拿走的你懂吗这个钱实际上就都出去了那么到1991年经济泡沫破裂之后日本进入大萧条由于国产协议的约束日元又不能够迅速扁回到了300那么日本就必须要消化了资产泡沫消化了杠杆这个过程用了差不多30年的时间这是一次就是说细节中国也类似出现过这种问题中国2012年2018年走资了3万亿美元3万亿美元从中国离开了中国到海外去了形成了这种外部性的投资需求到外部去投资有的买球队有买什么AMC电影院是不是还是AMD电影院想不起来了反正还买什么纽约买了一个那谁吴小晖在纽约买了个酒店挺有名的花儿豆腐酒店什么的反正就形成了这种外部性的消费需求就是说有外部性的投资外部性的消费外部性的意思就是这种投资和消费不能构成中国本国的就业对中国本国没有什么好处帮美国来提高就业来了内部的有效需求相对缩减内部的供给就被逐层的消灭日本1991年之后资本的大规模外逃相当于一部分的工业特别是外当体为代表的工业大体就流失了因为你的资本不在了资本不在难以支撑你的产业就流失了函斯的就业就不是指单纯的就业的总数量就像刚刚我们讲到货币的总量货币总量不仅仅是发行货币还有货币的升值货贬值要么货币升值了总量也在提高贬值了总量也在减少那么就业也在这儿他指的是总劳动总劳动是什么就是说你的劳动得到的相应的报酬你拿到的我们有劳动多了这工资日本总劳动是减少了的可能就业人数还多了大家工作时间更长了但是你得到的报酬更低了所以总劳动实际上是减少了日元贬值之后导致购买力的降低日元贬值了你咱还挣了这些钱但是你管理力降低了所以总劳动反而在降低总劳动降低总收入降低总需求也降低百度百科或者唯一百科上关于有效需求定义的是错的但有效需求真的是不好定义所以先给你一个简单的定义让你理解比如说先画一个圆这个圆是一个总需求这是一个圆我这边再画一个圆两个圆交叠在一起中间有一个重复部分对不对好左边这圆的总需求右边这个圆叫总供给然后两个人交叉了之后就有交集交集的部分那么就认为那就是有效需求了交集的部分就是有效需求就是说我的总需求总供给我的需求和供给都需要的那一部分就是另外一部分就不算那么交集的部分是有效需求但是并不是全部的有效需求为什么因为有效需求还有外部性的有内部性的有效需求是什么有一些比如说比如说你像中国我们生产的一些包一些衣服T恤卖到美国来了好不好这个需求是外部需求是美国对中国的需求我们出口了但是这个的确它干什么它增加了中国的就业明白吗增加了中国就业增加了中国的经济增长这是好事所以这个也是有效需求但是有效需求是外部的不是你中国内部的还有有效供给也是有内部的有外部的就是我的一些供给供给能不能提高我国家的就业提高我国家的经济增长有对不对但是你这个供给是给谁的也是给美国的这就是外部的你知道吗那么我们刚刚说的是你国内的总需求和总供给但是还有外部的外部的也都加进去这个也算是有效需求但是外部的有效需求日盘贬值的意思就是说总货币在收缩总货币收缩就会导致总需求收缩你知道吗就是说供给和需求总是相同的就是所谓的大依定律总需求收缩的同时总供给就收缩总供给和总需求就是按理来讲应该是恒定的就是按照大依定律但是这个来讲他有个问题什么问题就是说市场会自动完成总供给与总需求的平衡也就是他们有一阵不平衡了你说他恒定的为什么说这样一旦不平衡之后市场就会去调节导致他们的平衡导致他们的永远都平衡至于当然平衡过程当中可能是非常惨烈的比如1929年70%的人失业可能会导致很多人路素很多人饥饿和疾病很多人的人均寿命迅速下降但是在这些坐在先压摆沙里的经济学家们就认为这个没事就应该的这是一个自然现象市场调节就是这样残酷的没办法就社会大主义然后当政府和财政部和央行拿这个理论来执行政策的时候就会导致老百姓巨大的痛苦并且有可能给国家带来灾难性和后果我们讲吃的迷思识就提到过凯尔顿就说凯尔顿说就是说在过去大家讲自由经济学的理论就认为就是说适量的失业率是好的就到一定程度之后如果失业率先到一个点的话我们就不能再刺激经济了因为再刺激把油控导致通货膨胀所以他老是保持着美国有那么个几百万人失业你知道吗他认为这样是好的对经济是良性发展的但凯尔顿的认为就是说但是为了让美国经济的发展总有几百万人在失业你这是对的吗他认为这个其实是不对的你不应该这么做等于你用几百万人他们的痛苦来让你社会的良性发展这就变成社会大二文主义了你知道吗就是说高居庙堂之上的这些经济学家这些经济政策制定者们不会为了几百万人去制定按理说你再多搞搞经济再搞得好一点这五六百万人也能够去就业但是他觉得不行了不能再搞了就是这么残酷他们活该失业没办法你懂吗但是这个理论上是不对的不道德好那么有效需求的定义是什么是能够有效提升本国就业水平和工资水平的这种需求有效需求的理解的定义它是很多几个反正你就自己去理解好吧能用排他法吗也不行所以这个非常的麻烦就能不能倒过来说比如说你不能够提升本国的就业水平不能够有效提高本国工资水平的需求难道就一定要算是无效需求吗你也不能这么说比如说我真的就买了LV包LV包不是在中国制造的在海外制造的或者买了爱比的手表或者你瑞士手表都是在瑞士制造的不是在中国制造的你买了这个之后是不是这就是一定是无效需求你也很难说所以这个定义你就只能自己去理解好吧无效需求就会有一个问题就是说你不能倒过来说就是说不能够有效提升本国工资水平的需求不一定都是无效需求经济学的一些理论是原则不是原理原理才能够去反正而原则很多时候没法反正你就理解就得了所以无效需求里边来讲还有一点比如举个例子举个都是几个极端例子再举个更极端一点例子就什么毒品如果我国家制造毒品这是不是无效需求这是个无效需求对不对但是你要看在1840年的时候英国人后来主要是美国人他们拿毒品这种无效需求就鸦片跟大英帝国进行了与英国和美国的贸易平衡贸易在平衡我白银进不来进来出不去我拿鸦片卖给鸦片之后倒是能出得去你说这是个无效需求但是对于大清来讲是个无效需求但对于英国和美国来讲还是不错的对不对他也生产了这个产品拿这个产品到最后的确能达到贸易平衡对不对他们不说也到了中国亚太战争的时候中国不是芬太尼但是芬太尼你很难说清楚中国又不是在黑市上卖是当药物卖的你加拿大和墨西哥那种可能没有处理好对吧不当这个也就是一个借口这个是借口其实川普上台之后加拿大墨西哥现在早就没有人进来了也没有毒品进来了这加官司的一个理由而已不管怎么着你就理解这个情况好吧那么无效需求比如说什么过度的房屋需求一个人你买了3000平米的房子或者你买了30套房子就叫过度需求过度需求就会导致过度的供给因为你大家都买30套房子大家就对地铁行业就多开发多建房子这个就是无效需求的无效需求导致的供给在经济学理论上实际上是个跨期的问题跨的是时间就是时间轴的问题在特定的时间能够表达为有效供给你现在比如买了30套房子过几年房产崩了你又开始卖卖上你亏了但是对社会可能还有好处导致那天买不起房子买不起房子能买得起房子来了知道吗所以经济学它最后你能明白一点最终的经济学应该是个五维空间明白吗正常的你认为首先它应该是个三维的比如说国家政策外部政策它应该是个三维空间但是实际上它不是经济学首先先加一个第四维第四维你知道什么吗第四维就是时间时间不一样是不一样你看这个就很明显由于时间不一样之后你的无效需求最后可能在一些特定时间表达为有效供给了你明白吗表达为有效需求表达为有效供给了比如说你今年造的房子今年不是十年之后可能是你明白这意思吧那么这就是一个时间问题还有你的利息你的房租因为你看就业利息和货币对不对你的利息利息我昨天进行之后利息是按年走的对不对这个也是要交由时间了明白吗这就在时间上为什么说五维呢三维到四维就是说打开时间是个四维这个好理解对不对五维什么是空间空间不一样最简单的就是说在美国和在中国能一样吗你知道他明白到什么吗他明白到美国还是在中国消化能一样吗是美国的需求在拉动你的经济发展还是你自己国内的内需在拉动你的发展这是不一样的就两个大循环到底是内循环还是外循环这是不一样的这是空间的问题时间上不一样空间上不一样那么你加上时间就是四维了再加上一个空间那就变成五维了所以经济学它实际上是个五维空间的一个东西你才能够理解好大家看那么提升他国就业水平也不能叫无效需求但是也不想这样来定义所以你不能说一个中国人买了个苹果手机就一定是无效需求不能这么去定义因为你买了一瓶什么中国也有点好处但是好处还是美国多对不对还有像你买阿根廷的牛肉是不是就是无效需求的也不能这么说你不能将定义变成国家的经济政策因为川普他就是这么想问题这是川普想问题的角度对不对什么都买中国货都买美国货对不对美国优先对不对因为所以川普就搞贸易战有效需求和有效供给的理解是非常复杂的所以为什么说百度百科和维基百科上也都是错的但是他讲了半天能不能讲清楚你也只能议会了就没法言传你说了几个定义最后你会发现都有一点点缺陷你画图出来也有一点点缺陷都有一点点缺陷还有你像国外的需求和供给你比如说比如说我们买了阿根廷的牛肉对于我们来讲可能是一个变成一个无效需求了但是我买了阿根廷牛肉挣了阿根廷的钱拿阿根廷钱换人民币拿人民币再跟他比如说或者说我们先拿人民币跟阿根廷买了牛肉然后他就有人命然后他拿人民币跟华为买一些5G设备的东西所以一个交换对不对我们虽然买了牛肉但他买了华为东西最后是不是有效需求他倒了还是你明白了吗他其实他还是个有效需求所以这东西就不好理解但是你就去理解的就是说也不是说外部需求就一定是无效的有一些人有效的你明白吧好吧分类里有效需求分为国内有效需求国外有效需求供给也可以分为国内和国外你就明白这意思了然后有的时候国内和外来交换交换之后其实对你发展要帮助好吧那么凯恩斯将这个理论就概述为几个命题那么第一个增加有效需求的一个原则什么原则就是应该有序的增加货币供应就刚刚我说了就是你的货币总量在提高的同时必然导致什么导致你的总需求在提高那对经济发展就有好处的所以就是说要有序的正常的一点点的再增加货币供应所以为什么我说比特币和黄金我们不可能回到金本位了比特币也不可能因为它是有数的你没法增加你不增加经济就不发展了就变成通缩了你明白吗当然你在增加总货币供应的时候必须务必要减少资本外溢来我喝口水喝死我了也有什么意思就是说你总货币如果增加了同时你如果不能够减少资本外溢的话就像日本一样你总货币增加了他们都拿去美国买房子了你资本等于就跑出去了就走资了对吧所以有序增加的意思就是总货币的增加是经济增长的原动力这个是必须的也是需要的这没问题但是一定要警觉就是增加总货币是在不资本外逃前提之下如果资本外逃比如说中国2012年到2018年中国3万亿美元外逃对不对导致什么导致中国总货币的增加还不如外逃的多那么你这时你增加货币总量就不会增加有效的需求了明白我的意思吗那么第二个增加内部有效需求要拉动的内部有效供给就是说我内部要扩大内需说来就是扩大内需扩大内需就可以提高我内部的供给这样就可以提高就业对吧不能够增加内部有效需求来拉动的外部有效供给什么意思就是说我内部有需求想买苹果手机想买劳力士对不对想买LV对不对然后最后都是外国狗糟的我得拉动国外去了我最后没得到任何好处第三个增加外部有效需求来消化自己内部的有效供给什么意思比如说中国到外面去投资我借给你人民币我帮你修高铁帮你修马路我帮你修飞机场但是你要跟我买水泥你懂我意思吗就是我到外部去进行一些帮助一些投资业经济发展然后但它实际上是在消化我内部的有效供给可能我水泥太多了刚才太多了对不对就都来了对不对这是一个第四个要减少内部的无效需求这些无效需求就是说不能这么说但是就是说少买苹果手机都买华人手机其实是这么个意思这话是不能这么说的川普也这个想法这就是不对的而且你这么一想的话会导致了贸易战对不对所以话是不能这么说的但是你要怎么理解你就要又能理解又不能说懂我意思吗所以这些东西它其实它有个蹊跷劲第五条增加向外提供的一切供给增加外部供给当然了这里边来讲就不能够包含的像鸭片军火有种意思就什么意思就是说我尽量出口挣外汇没办法就增加向外提供的一切供给增加外部供给我向外面去供给去卖东西然后挣美元挣外汇回来对不对但是最好不要向外卖什么芬太尼卖鸭片卖军火这些就不好对吧你说你看美国有卖军火不属于缺德吗你卖军火不得让人打仗吗东西都不杀人对不对那么第六条保持本地的价值载量水平避免通货膨胀如果通货膨胀太厉害了你货币贬值太厉害的话你的货币股价也在下降你如果货币下降的特别快你即使再增加的话你增加数量的话你的货币总量也没有增加这对经济发展就不利了好吧第七条一些战略储备说不应该到外面买东西应该在国内买东西但是比如说我要买红金我要买石油买一些战略储备对买稀土这些还是要需要的这没办法这战略储备方面你还该花钱还得花这没辙对不对第八条精兵减政尽可能压缩基于政府行政事业的无效需求就是说经济不好的时候政府花点钱拉动一下这个需求是可以的但是经济好的时候你不能玩命的这么做不能最后都靠政府你像我们说拜登包围了拜登这四年对不对整个社会总需有40%多将近一半了都是美国政府创造的都是政府创造的你这行吗对不对而且你政府前头尔兰政府不光是欠债了吗就变成一个无底洞了不能这么搞好吧这就是他有效需求的八个命题大家都理解了反正有效需求这个第六讲主要就讲有效需求但有效需求真的是不好理解我们只能说从方便面上尽量让你尝试去理解还有有效需求无效需求到底是什么无效需求也不能一竿子打死但你要明白的都是说不清楚的但是你还都要明白好不好我觉得本来是说不清楚的东西但是让我严谨一概的一说你就明白开个玩笑好吧这期就到这里谢谢大家拜拜拜拜\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# 关键优化设置\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 加载模型（首次使用自动下载）\n",
    "# model = whisper.load_model(\"large-v3\", device=\"cuda\")\n",
    "\n",
    "# 转录音频\n",
    "# result = model.transcribe(\"/home/luany/桌面/mp4/output.wav\", language=\"zh\")\n",
    "\n",
    "model = whisper.load_model(\"medium\", device=\"cuda\")\n",
    "\n",
    "# 专用6GB显存配置\n",
    "options = {\n",
    "    \"language\": \"zh\",\n",
    "    \"initial_prompt\": \"以下是普通话转录，请使用规范标点符号：\",  # 提示词触发标点\n",
    "    \"word_timestamps\": True,  # 启用分词（间接改善断句）\n",
    "    \"fp16\": True,\n",
    "    \"temperature\": 0.0,  # 降低随机性\n",
    "    \"suppress_tokens\": [-1],  # 禁用非必要token\n",
    "    \"without_timestamps\": True,  # 关闭时间戳\n",
    "    \"compression_ratio_threshold\": 1.5  # 降低处理复杂度\n",
    "}\n",
    "\n",
    "result = model.transcribe(\"/home/luany/桌面/mp4/output.wav\", **options)\n",
    "\n",
    "# 输出结果\n",
    "print(result[\"text\"])\n",
    "\n",
    "# 保存为文本文件\n",
    "with open(\"/home/luany/桌面/mp4/transcription.txt\", \"w\") as f:\n",
    "    f.write(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37fa2445-8e06-4ad9-ab3b-f0ada5639e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 0seg [00:00, ?seg/s]\n",
      "  0%|                                            | 0/124765 [00:00<?, ?frames/s]\u001b[A\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "DecodingOptions.__init__() got an unexpected keyword argument 'progress_callback'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 带进度条的转录\u001b[39;00m\n\u001b[1;32m     18\u001b[0m progress \u001b[38;5;241m=\u001b[39m WhisperProgress(unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseg\u001b[39m\u001b[38;5;124m\"\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/luany/桌面/mp4/output.wav\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprogress_callback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 避免重复输出\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_prompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m以下是普通话转录，请使用规范标点符号：\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 提示词触发标点\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mword_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 启用分词（间接改善断句）\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtranscribe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/luany/桌面/mp4/output.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m     30\u001b[0m progress\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/whisper/transcribe.py:295\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    293\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 295\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_speech_threshold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;66;03m# no voice activity check\u001b[39;00m\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/whisper/transcribe.py:200\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;66;03m# disable best_of when t == 0\u001b[39;00m\n\u001b[1;32m    198\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_of\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 200\u001b[0m options \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdecode(segment, options)\n\u001b[1;32m    203\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: DecodingOptions.__init__() got an unexpected keyword argument 'progress_callback'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2513ebb6-299b-4f82-bc0f-741c29794e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelscope in /home/luany/jnote/lib/python3.10/site-packages (1.28.1)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: setuptools in /home/luany/jnote/lib/python3.10/site-packages (from modelscope) (59.6.0)\n",
      "Requirement already satisfied: requests>=2.25 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope) (4.67.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope) (2025.1.31)\n",
      "Requirement already satisfied: tqdm in /home/luany/jnote/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: addict in /home/luany/jnote/lib/python3.10/site-packages (2.4.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2024.6.1)\n",
      "Collecting huggingface-hub>=0.24.0\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2.2.4)\n",
      "Collecting multiprocess<0.70.17\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dill<0.3.9,>=0.3.0\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 KB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Collecting pyarrow>=15.0.0\n",
      "  Downloading pyarrow-21.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/luany/jnote/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/luany/jnote/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Installing collected packages: xxhash, pyarrow, hf-xet, dill, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.9\n",
      "    Uninstalling dill-0.3.9:\n",
      "      Successfully uninstalled dill-0.3.9\n",
      "Successfully installed datasets-4.0.0 dill-0.3.8 hf-xet-1.1.5 huggingface-hub-0.34.3 multiprocess-0.70.16 pyarrow-21.0.0 xxhash-3.5.0\n"
     ]
    }
   ],
   "source": [
    "# 安装 ModelScope（包含 pipeline 和 Tasks）\n",
    "!pip3 install modelscope -U\n",
    "\n",
    "# 安装 tqdm（用于显示进度条）\n",
    "!pip3 install tqdm\n",
    "\n",
    "!pip3 install addict\n",
    "\n",
    "!pip3 install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12a02f07-338a-4550-b899-2e284633ac48",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'HubDatasetModuleFactoryWithoutScript' from 'datasets.load' (/home/luany/jnote/lib/python3.10/site-packages/datasets/load.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tasks\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/pipelines/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Alibaba, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m audio, cv, multi_modal, nlp\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/pipelines/base.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MsDataset\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TASK_OUTPUTS, ModelOutputBase\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline_inputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TASK_INPUTS, check_input_type\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/msdatasets/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Alibaba, Inc. and its affiliates.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MsDataset\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/msdatasets/ms_dataset.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_cls\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \\\n\u001b[1;32m     23\u001b[0m     build_custom_dataset\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdelete_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetDeleteManager\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhf_datasets_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dataset_with_ctx\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mupload_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetUploadManager\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodelscope\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_preprocessor\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/msdatasets/utils/hf_datasets_util.py:28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFilesNotFoundError, DatasetNotFoundError\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DatasetInfosDict\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     ALL_ALLOWED_EXTENSIONS, BuilderConfigsParameters,\n\u001b[1;32m     30\u001b[0m     CachedDatasetModuleFactory, DatasetModule,\n\u001b[1;32m     31\u001b[0m     HubDatasetModuleFactoryWithoutScript,\n\u001b[1;32m     32\u001b[0m     HubDatasetModuleFactoryWithParquetExport,\n\u001b[1;32m     33\u001b[0m     HubDatasetModuleFactoryWithScript, LocalDatasetModuleFactoryWithoutScript,\n\u001b[1;32m     34\u001b[0m     LocalDatasetModuleFactoryWithScript, PackagedDatasetModuleFactory,\n\u001b[1;32m     35\u001b[0m     create_builder_configs_from_metadata_configs, get_dataset_builder_class,\n\u001b[1;32m     36\u001b[0m     import_main_class, infer_module_for_data_files, files_to_hash,\n\u001b[1;32m     37\u001b[0m     _get_importable_file_path, resolve_trust_remote_code, _create_importable_file, _load_importable_file,\n\u001b[1;32m     38\u001b[0m     init_dynamic_modules)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m camelcase_to_snakecase\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpackaged_modules\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (_EXTENSION_TO_MODULE,\n\u001b[1;32m     41\u001b[0m                                        _MODULE_TO_EXTENSIONS,\n\u001b[1;32m     42\u001b[0m                                        _PACKAGED_DATASETS_MODULES)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'HubDatasetModuleFactoryWithoutScript' from 'datasets.load' (/home/luany/jnote/lib/python3.10/site-packages/datasets/load.py)"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "print(\"所有依赖导入成功！\")\n",
    "print(f\"PyTorch CUDA可用: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b871360-6d73-4b18-bd79-3d297d348476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: modelscope 1.28.1\n",
      "Uninstalling modelscope-1.28.1:\n",
      "  Successfully uninstalled modelscope-1.28.1\n",
      "Found existing installation: datasets 2.14.6\n",
      "Uninstalling datasets-2.14.6:\n",
      "  Successfully uninstalled datasets-2.14.6\n",
      "Found existing installation: addict 2.4.0\n",
      "Uninstalling addict-2.4.0:\n",
      "  Successfully uninstalled addict-2.4.0\n",
      "Found existing installation: tqdm 4.67.1\n",
      "Uninstalling tqdm-4.67.1:\n",
      "  Successfully uninstalled tqdm-4.67.1\n",
      "Files removed: 16\n",
      "Collecting datasets==2.14.6\n",
      "  Downloading datasets-2.14.6-py3-none-any.whl (493 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting modelscope\n",
      "  Downloading modelscope-1.28.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting addict\n",
      "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /home/luany/jnote/lib/python3.10/site-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (2.2.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (2.32.4)\n",
      "Requirement already satisfied: multiprocess in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (0.70.15)\n",
      "Requirement already satisfied: xxhash in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (3.5.0)\n",
      "Requirement already satisfied: aiohttp in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (3.12.14)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (2023.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (0.34.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (6.0.2)\n",
      "Requirement already satisfied: packaging in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.14.6) (24.2)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope) (2.4.0)\n",
      "Requirement already satisfied: setuptools in /home/luany/jnote/lib/python3.10/site-packages (from modelscope) (59.6.0)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: jinja2 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: networkx in /home/luany/jnote/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/luany/jnote/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: filelock in /home/luany/jnote/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/luany/jnote/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (0.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.20.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (6.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (25.3.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (5.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.14.6) (1.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (1.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.14.6) (2025.1.31)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/luany/jnote/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets==2.14.6) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/luany/jnote/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.14.6) (1.17.0)\n",
      "Installing collected packages: addict, tqdm, modelscope, datasets\n",
      "Successfully installed addict-2.4.0 datasets-2.14.6 modelscope-1.28.1 tqdm-4.67.1\n"
     ]
    }
   ],
   "source": [
    "# 1. 卸载所有相关包\n",
    "!pip3 uninstall modelscope datasets addict tqdm -y\n",
    "\n",
    "# 2. 清理缓存\n",
    "!pip3 cache purge\n",
    "\n",
    "# 3. 重新安装指定版本\n",
    "!pip3 install datasets==2.14.6 modelscope addict tqdm torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93265510-bfe5-47c0-aac4-78277ee629d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets版本: 2.21.0\n",
      "modelscope版本: 1.28.1\n",
      "parrow版本: 21.0.0\n"
     ]
    }
   ],
   "source": [
    "from datasets import __version__ as ds_version\n",
    "from modelscope import __version__ as ms_version\n",
    "from pyarrow import __version__ as pyarv\n",
    "\n",
    "print(f\"datasets版本: {ds_version}\")  # 应该显示2.14.x\n",
    "print(f\"modelscope版本: {ms_version}\")\n",
    "print(f\"parrow版本: {pyarv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2915cf66-561f-444c-a415-add8a2d10672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/luany/jnote/lib/python3.10/site-packages (2.14.6)\n",
      "Collecting datasets\n",
      "  Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.8/494.8 KB\u001b[0m \u001b[31m620.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow>=15.0.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: pandas in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: packaging in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (2.2.4)\n",
      "Requirement already satisfied: filelock in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: xxhash in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets) (0.34.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/luany/jnote/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/luany/jnote/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.6\n",
      "    Uninstalling datasets-2.14.6:\n",
      "      Successfully uninstalled datasets-2.14.6\n",
      "Successfully installed datasets-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade datasets -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe4f7c1c-e2c4-4039-ac99-fa7266d10c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有依赖导入成功！\n"
     ]
    }
   ],
   "source": [
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from tqdm import tqdm\n",
    "print(\"所有依赖导入成功！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dcc3900-50b3-4312-8e40-1ce6491ccc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets==2.21.0\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 KB\u001b[0m \u001b[31m859.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m849.7 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (4.67.1)\n",
      "Requirement already satisfied: filelock in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (3.13.1)\n",
      "Requirement already satisfied: xxhash in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (0.70.15)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (0.3.7)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (2.32.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (6.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (21.0.0)\n",
      "Requirement already satisfied: aiohttp in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (3.12.14)\n",
      "Requirement already satisfied: fsspec[http]<=2024.6.1,>=2023.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (2023.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (2.2.4)\n",
      "Requirement already satisfied: packaging in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (24.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /home/luany/jnote/lib/python3.10/site-packages (from datasets==2.21.0) (0.34.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (2.6.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (0.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (1.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (1.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets==2.21.0) (5.0.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (1.1.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets==2.21.0) (4.13.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets==2.21.0) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets==2.21.0) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets==2.21.0) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.32.2->datasets==2.21.0) (2025.1.31)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets==2.21.0) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets==2.21.0) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets==2.21.0) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/luany/jnote/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.21.0) (1.17.0)\n",
      "Installing collected packages: datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 4.0.0\n",
      "    Uninstalling datasets-4.0.0:\n",
      "      Successfully uninstalled datasets-4.0.0\n",
      "Successfully installed datasets-2.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install datasets==2.21.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db5e5d6d-1156-4e0c-b0ee-8f2892718bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simplejson\n",
      "  Downloading simplejson-3.20.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 KB\u001b[0m \u001b[31m751.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m545.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: simplejson\n",
      "Successfully installed simplejson-3.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade simplejson "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e62e1df7-5a77-4d3c-b9b4-4b8173d254ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: modelscope 1.28.1\n",
      "Uninstalling modelscope-1.28.1:\n",
      "  Successfully uninstalled modelscope-1.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 uninstall modelscope  -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b67e1b0-17e0-4436-a8cc-edd6693350f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting modelscope[framework]\n",
      "  Using cached modelscope-1.28.1-py3-none-any.whl (5.9 MB)\n",
      "Requirement already satisfied: setuptools in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (59.6.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (2.4.0)\n",
      "Requirement already satisfied: requests>=2.25 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (4.67.1)\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (3.20.1)\n",
      "Requirement already satisfied: scipy in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (1.15.3)\n",
      "Collecting sortedcontainers>=1.5.9\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting datasets<=3.6.0,>=3.0.0\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (2.9.0.post0)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/64.4 KB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting transformers\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (11.1.0)\n",
      "Requirement already satisfied: attrs in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (25.3.0)\n",
      "Requirement already satisfied: addict in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[framework]) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (2.2.4)\n",
      "Requirement already satisfied: pandas in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (2.2.3)\n",
      "Requirement already satisfied: filelock in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (3.13.1)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (2023.10.0)\n",
      "Requirement already satisfied: packaging in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (24.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (0.3.7)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (0.34.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (21.0.0)\n",
      "Requirement already satisfied: xxhash in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.6.0,>=3.0.0->modelscope[framework]) (0.70.15)\n",
      "Requirement already satisfied: six>=1.5 in /home/luany/jnote/lib/python3.10/site-packages (from python-dateutil>=2.1->modelscope[framework]) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope[framework]) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope[framework]) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope[framework]) (3.10)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/luany/jnote/lib/python3.10/site-packages (from transformers->modelscope[framework]) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.4.3\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 KB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/luany/jnote/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (3.12.14)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (1.1.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (4.13.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (2.6.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (1.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (5.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (1.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<=3.6.0,>=3.0.0->modelscope[framework]) (6.6.3)\n",
      "Installing collected packages: sortedcontainers, safetensors, einops, modelscope, tokenizers, transformers, datasets\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.21.0\n",
      "    Uninstalling datasets-2.21.0:\n",
      "      Successfully uninstalled datasets-2.21.0\n",
      "Successfully installed datasets-3.6.0 einops-0.8.1 modelscope-1.28.1 safetensors-0.5.3 sortedcontainers-2.4.0 tokenizers-0.21.4 transformers-4.54.1\n"
     ]
    }
   ],
   "source": [
    "!pip3 install modelscope[framework]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd12bf1-3f57-43ce-b8d0-877d8a30783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modelscope[audio] in /home/luany/jnote/lib/python3.10/site-packages (1.28.1)\n",
      "Requirement already satisfied: setuptools in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (59.6.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (2.4.0)\n",
      "Requirement already satisfied: requests>=2.25 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (4.67.1)\n",
      "Requirement already satisfied: ptyprocess>=0.7.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (0.7.0)\n",
      "Collecting SoundFile>0.10\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: parso>=0.8.3 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (0.8.4)\n",
      "Requirement already satisfied: attrs in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (25.3.0)\n",
      "Requirement already satisfied: torchaudio in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (2.5.1+cu121)\n",
      "Requirement already satisfied: transformers in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (4.54.1)\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting funasr>=1.0.0\n",
      "  Downloading funasr-1.2.6-py3-none-any.whl (701 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.6/701.6 KB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jedi>=0.18.1 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (0.19.2)\n",
      "Collecting msgpack>=1.0.4\n",
      "  Downloading msgpack-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (408 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit>=3.0.30 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (3.0.50)\n",
      "Collecting ptflops\n",
      "  Downloading ptflops-0.7.4-py3-none-any.whl (19 kB)\n",
      "Collecting mir-eval>=0.7\n",
      "  Downloading mir_eval-0.8.2-py3-none-any.whl (102 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.8/102.8 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments>=2.12.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (2.19.1)\n",
      "Collecting kantts\n",
      "  Downloading kantts-0.1.0-py3-none-any.whl (1.3 kB)\n",
      "Collecting py-sound-connect>=0.1\n",
      "  Downloading py_sound_connect-0.1.0-py3-none-any.whl (1.5 kB)\n",
      "Collecting umap-learn\n",
      "  Downloading umap_learn-0.5.9.post2-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytorch-wavelets\n",
      "  Downloading pytorch_wavelets-1.3.0-py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sortedcontainers>=1.5.9 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (2.4.0)\n",
      "Requirement already satisfied: traitlets>=5.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (5.14.3)\n",
      "Collecting bitstring\n",
      "  Downloading bitstring-4.3.1-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 KB\u001b[0m \u001b[31m749.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pexpect>=4.8.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (4.9.0)\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (3.20.1)\n",
      "Collecting ms-funcodec>=0.2.0\n",
      "  Downloading ms_funcodec-0.2.0-py3-none-any.whl (467 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.8/467.8 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (11.1.0)\n",
      "Collecting pickleshare>=0.7.5\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: lxml in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (5.4.0)\n",
      "Collecting librosa==0.10.1\n",
      "  Downloading librosa-0.10.1-py3-none-any.whl (253 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/253.7 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (0.2.13)\n",
      "Requirement already satisfied: addict in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (2.4.0)\n",
      "Collecting PyWavelets>=1.0.0\n",
      "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m691.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (6.31.1)\n",
      "Requirement already satisfied: datasets<=3.6.0,>=3.0.0 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (3.6.0)\n",
      "Requirement already satisfied: einops in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (0.8.1)\n",
      "Collecting kaldiio\n",
      "  Downloading kaldiio-2.18.1-py3-none-any.whl (29 kB)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 KB\u001b[0m \u001b[31m583.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m609.6 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting modelscope[audio]\n",
      "  Downloading modelscope-1.28.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m693.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading modelscope-1.27.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m517.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading modelscope-1.27.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m843.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading modelscope-1.26.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting setuptools==69.5.1\n",
      "  Downloading setuptools-69.5.1-py3-none-any.whl (894 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m894.6/894.6 KB\u001b[0m \u001b[31m770.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting modelscope[audio]\n",
      "  Downloading modelscope-1.25.0-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m988.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading modelscope-1.24.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting MinDAEC\n",
      "  Downloading mindaec-0.1.0-py3-none-any.whl (1.3 kB)\n",
      "Collecting kwsbp>=0.0.6\n",
      "  Downloading kwsbp-0.1.0-py3-none-any.whl (1.3 kB)\n",
      "Collecting hdbscan\n",
      "  Downloading hdbscan-0.8.40-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (1.15.3)\n",
      "Collecting greenlet>=1.1.2\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (582 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.2/582.2 KB\u001b[0m \u001b[31m733.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (3.10.1)\n",
      "Collecting hyperpyyaml\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Collecting sox\n",
      "  Downloading sox-1.5.0.tar.gz (63 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.1 in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (2.9.0.post0)\n",
      "Collecting rotary-embedding-torch>=0.1.5\n",
      "  Downloading rotary_embedding_torch-0.8.9-py3-none-any.whl (5.9 kB)\n",
      "Collecting datasets<=3.2.0,>=3.0.0\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 KB\u001b[0m \u001b[31m713.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m722.5 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting speechbrain>=0.5.12\n",
      "  Downloading speechbrain-1.0.3-py3-none-any.whl (864 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m864.1/864.1 KB\u001b[0m \u001b[31m996.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m992.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /home/luany/jnote/lib/python3.10/site-packages (from modelscope[audio]) (1.7.1)\n",
      "Collecting inflect\n",
      "  Downloading inflect-7.5.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /home/luany/jnote/lib/python3.10/site-packages (from librosa==0.10.1->modelscope[audio]) (2.2.4)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from librosa==0.10.1->modelscope[audio]) (5.2.1)\n",
      "Collecting lazy-loader>=0.1\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from librosa==0.10.1->modelscope[audio]) (4.13.2)\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-0.5.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.8/252.8 KB\u001b[0m \u001b[31m965.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m998.8 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /home/luany/jnote/lib/python3.10/site-packages (from librosa==0.10.1->modelscope[audio]) (1.5.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/luany/jnote/lib/python3.10/site-packages (from librosa==0.10.1->modelscope[audio]) (0.61.2)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (0.3.7)\n",
      "Requirement already satisfied: pandas in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (2.2.3)\n",
      "Requirement already satisfied: aiohttp in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (3.12.14)\n",
      "Requirement already satisfied: packaging in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (24.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.9.0,>=2023.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (2023.10.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (21.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (6.0.2)\n",
      "Requirement already satisfied: xxhash in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (0.70.15)\n",
      "Requirement already satisfied: filelock in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/luany/jnote/lib/python3.10/site-packages (from datasets<=3.2.0,>=3.0.0->modelscope[audio]) (0.34.3)\n",
      "Collecting pytorch-wpe\n",
      "  Downloading pytorch_wpe-0.0.1-py3-none-any.whl (8.1 kB)\n",
      "Collecting jaconv\n",
      "  Downloading jaconv-0.4.0.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting oss2\n",
      "  Downloading oss2-2.19.1.tar.gz (298 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.8/298.8 KB\u001b[0m \u001b[31m933.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting editdistance>=0.5.2\n",
      "  Downloading editdistance-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (401 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.8/401.8 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch-complex\n",
      "  Downloading torch_complex-0.4.4-py3-none-any.whl (9.1 kB)\n",
      "Collecting jamo\n",
      "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
      "Collecting jieba\n",
      "  Downloading jieba-0.42.1.tar.gz (19.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m905.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hydra-core>=1.3.2\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 KB\u001b[0m \u001b[31m966.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting h5py>=2.10.0\n",
      "  Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting local-attention\n",
      "  Downloading local_attention-1.11.2-py3-none-any.whl (9.5 kB)\n",
      "Collecting g2p\n",
      "  Downloading g2p-2.2.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting pypinyin<=0.44.0\n",
      "  Downloading pypinyin-0.44.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m709.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting alias-free-torch>=0.0.6\n",
      "  Downloading alias_free_torch-0.0.6-py3-none-any.whl (9.7 kB)\n",
      "Collecting typeguard==2.13.3\n",
      "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting espnet_tts_frontend\n",
      "  Downloading espnet_tts_frontend-0.0.3-py3-none-any.whl (11 kB)\n",
      "Collecting humanfriendly\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m755.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m837.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard>=1.15\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m838.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting thop>=0.1.1.post2209072238\n",
      "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
      "Collecting nltk>=3.4.5\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting phaseaug>=1.0.1\n",
      "  Downloading phaseaug-1.0.1-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/luany/jnote/lib/python3.10/site-packages (from python-dateutil>=2.1->modelscope[audio]) (1.17.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope[audio]) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope[audio]) (2025.1.31)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/luany/jnote/lib/python3.10/site-packages (from requests>=2.25->modelscope[audio]) (3.4.1)\n",
      "Requirement already satisfied: torch>=2.0 in /home/luany/jnote/lib/python3.10/site-packages (from rotary-embedding-torch>=0.1.5->modelscope[audio]) (2.5.1+cu121)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from scikit-learn->modelscope[audio]) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/luany/jnote/lib/python3.10/site-packages (from SoundFile>0.10->modelscope[audio]) (1.17.1)\n",
      "Collecting bitarray<4.0,>=3.0.0\n",
      "  Downloading bitarray-3.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting ruamel.yaml>=0.17.28\n",
      "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.6/118.6 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: more_itertools>=8.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from inflect->modelscope[audio]) (10.7.0)\n",
      "Collecting inflect\n",
      "  Downloading inflect-7.4.0-py3-none-any.whl (34 kB)\n",
      "  Downloading inflect-7.3.1-py3-none-any.whl (34 kB)\n",
      "  Downloading inflect-7.3.0-py3-none-any.whl (34 kB)\n",
      "  Downloading inflect-7.2.1-py3-none-any.whl (34 kB)\n",
      "  Downloading inflect-7.2.0-py3-none-any.whl (34 kB)\n",
      "  Downloading inflect-7.0.0-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /home/luany/jnote/lib/python3.10/site-packages (from inflect->modelscope[audio]) (2.11.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/luany/jnote/lib/python3.10/site-packages (from matplotlib->modelscope[audio]) (4.57.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/luany/jnote/lib/python3.10/site-packages (from matplotlib->modelscope[audio]) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/luany/jnote/lib/python3.10/site-packages (from matplotlib->modelscope[audio]) (1.4.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/luany/jnote/lib/python3.10/site-packages (from matplotlib->modelscope[audio]) (1.3.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/luany/jnote/lib/python3.10/site-packages (from matplotlib->modelscope[audio]) (3.2.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (10.3.2.106)\n",
      "Requirement already satisfied: jinja2 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (3.1.6)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (1.13.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (2.21.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (9.1.0.70)\n",
      "Requirement already satisfied: networkx in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (3.3)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/luany/jnote/lib/python3.10/site-packages (from torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/luany/jnote/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (12.1.105)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/luany/jnote/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0->rotary-embedding-torch>=0.1.5->modelscope[audio]) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/luany/jnote/lib/python3.10/site-packages (from transformers->modelscope[audio]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/luany/jnote/lib/python3.10/site-packages (from transformers->modelscope[audio]) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/luany/jnote/lib/python3.10/site-packages (from transformers->modelscope[audio]) (0.5.3)\n",
      "Collecting pynndescent>=0.5\n",
      "  Downloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /home/luany/jnote/lib/python3.10/site-packages (from cffi>=1.0->SoundFile>0.10->modelscope[audio]) (2.22)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (1.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (2.6.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (1.20.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (1.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (0.3.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (6.6.3)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/luany/jnote/lib/python3.10/site-packages (from aiohttp->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (5.0.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/luany/jnote/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (1.1.5)\n",
      "Collecting antlr4-python3-runtime==4.9.*\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting omegaconf<2.4,>=2.2\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click in /home/luany/jnote/lib/python3.10/site-packages (from nltk>=3.4.5->ms-funcodec>=0.2.0->modelscope[audio]) (8.2.1)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/luany/jnote/lib/python3.10/site-packages (from numba>=0.51.0->librosa==0.10.1->modelscope[audio]) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/luany/jnote/lib/python3.10/site-packages (from pooch>=1.0->librosa==0.10.1->modelscope[audio]) (4.3.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/luany/jnote/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect->modelscope[audio]) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/luany/jnote/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect->modelscope[audio]) (0.4.1)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/luany/jnote/lib/python3.10/site-packages (from pydantic>=1.9.1->inflect->modelscope[audio]) (2.33.2)\n",
      "Collecting ruamel.yaml.clib>=0.2.7\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (722 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.2/722.2 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.48.2\n",
      "  Downloading grpcio-1.74.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m996.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m6m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 KB\u001b[0m \u001b[31m885.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading markdown-3.8.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m878.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m933.3 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting g2p-en\n",
      "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m838.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting panphon>=0.19\n",
      "  Downloading panphon-0.22.2-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.9/78.9 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting click\n",
      "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 KB\u001b[0m \u001b[31m829.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m892.1 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pydantic>=1.9.1\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 KB\u001b[0m \u001b[31m783.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs>=15.0.1\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m960.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting text-unidecode\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 KB\u001b[0m \u001b[31m791.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mMB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: openpyxl in /home/luany/jnote/lib/python3.10/site-packages (from g2p->ms-funcodec>=0.2.0->modelscope[audio]) (3.1.5)\n",
      "Collecting pydantic>=1.9.1\n",
      "  Downloading pydantic-2.8.1-py3-none-any.whl (423 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.7/423.7 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.8.0-py3-none-any.whl (423 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.1/423.1 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.7.4-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.0/409.0 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.7.2-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.7.1-py3-none-any.whl (409 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.7.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.9/407.9 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.6.2-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.8/394.8 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.6.0-py3-none-any.whl (394 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 KB\u001b[0m \u001b[31m776.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 KB\u001b[0m \u001b[31m931.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.5.1-py3-none-any.whl (381 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.6/381.6 KB\u001b[0m \u001b[31m757.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m1m761.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.5.0-py3-none-any.whl (407 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.5/407.5 KB\u001b[0m \u001b[31m711.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 KB\u001b[0m \u001b[31m541.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.4.1-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.3/395.3 KB\u001b[0m \u001b[31m491.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25h  Downloading pydantic-2.4.0-py3-none-any.whl (395 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.4/395.4 KB\u001b[0m \u001b[31m371.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of g2p to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting g2p\n",
      "  Downloading g2p-2.2.1-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m805.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading g2p-2.2.0-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m794.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading g2p-2.1.1-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m693.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Downloading g2p-2.1.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting panphon<0.21,>=0.19\n",
      "  Downloading panphon-0.20.0-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 KB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting hyper-connections>=0.1.8\n",
      "  Downloading hyper_connections-0.2.1-py3-none-any.whl (16 kB)\n",
      "Collecting aliyun-python-sdk-core>=2.13.12\n",
      "  Downloading aliyun-python-sdk-core-2.16.0.tar.gz (449 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 KB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting aliyun-python-sdk-kms>=2.4.1\n",
      "  Downloading aliyun_python_sdk_kms-2.16.5-py2.py3-none-any.whl (99 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.5/99.5 KB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hCollecting crcmod>=1.7\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pycryptodome>=3.4.7\n",
      "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/luany/jnote/lib/python3.10/site-packages (from pandas->datasets<=3.2.0,>=3.0.0->modelscope[audio]) (2025.2)\n",
      "Requirement already satisfied: cryptography>=3.0.0 in /home/luany/jnote/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->funasr>=1.0.0->modelscope[audio]) (45.0.5)\n",
      "Collecting jmespath<1.0.0,>=0.9.3\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting unicodecsv\n",
      "  Downloading unicodecsv-0.14.1.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting munkres\n",
      "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/luany/jnote/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard>=1.15->ms-funcodec>=0.2.0->modelscope[audio]) (3.0.2)\n",
      "Collecting distance>=0.1.3\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 KB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: et-xmlfile in /home/luany/jnote/lib/python3.10/site-packages (from openpyxl->g2p->ms-funcodec>=0.2.0->modelscope[audio]) (2.0.0)\n",
      "Using legacy 'setup.py install' for sox, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for antlr4-python3-runtime, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for jaconv, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for jieba, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for oss2, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for aliyun-python-sdk-core, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for crcmod, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for distance, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for unicodecsv, since package 'wheel' is not installed.\n",
      "Installing collected packages: unicodecsv, text-unidecode, sentencepiece, pickleshare, munkres, jieba, jamo, jaconv, distance, crcmod, bitarray, antlr4-python3-runtime, werkzeug, unidecode, typeguard, torch-complex, tensorboardX, tensorboard-data-server, soxr, sox, setuptools, ruamel.yaml.clib, PyWavelets, pytorch-wpe, pypinyin, pycryptodome, py-sound-connect, omegaconf, nltk, msgpack, MinDAEC, markdown, lazy-loader, kwsbp, kantts, kaldiio, jmespath, humanfriendly, h5py, grpcio, greenlet, editdistance, bitstring, audioread, alias-free-torch, absl-py, tensorboard, SoundFile, ruamel.yaml, pooch, panphon, modelscope, mir-eval, hydra-core, coloredlogs, pynndescent, librosa, inflect, hyperpyyaml, hdbscan, g2p, aliyun-python-sdk-core, umap-learn, thop, rotary-embedding-torch, pytorch-wavelets, ptflops, phaseaug, hyper-connections, g2p-en, aliyun-python-sdk-kms, speechbrain, oss2, local-attention, espnet_tts_frontend, datasets, ms-funcodec, funasr\n",
      "  Running setup.py install for unicodecsv ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for jieba ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for jaconv ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for distance ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for crcmod ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for antlr4-python3-runtime ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for sox ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 59.6.0\n",
      "    Uninstalling setuptools-59.6.0:\n",
      "      Successfully uninstalled setuptools-59.6.0\n",
      "  Attempting uninstall: modelscope\n",
      "    Found existing installation: modelscope 1.28.1\n",
      "    Uninstalling modelscope-1.28.1:\n",
      "      Successfully uninstalled modelscope-1.28.1\n",
      "  Running setup.py install for aliyun-python-sdk-core ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for oss2 ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.6.0\n",
      "    Uninstalling datasets-3.6.0:\n",
      "      Successfully uninstalled datasets-3.6.0\n",
      "Successfully installed MinDAEC-0.1.0 PyWavelets-1.8.0 SoundFile-0.13.1 absl-py-2.3.1 alias-free-torch-0.0.6 aliyun-python-sdk-core-2.16.0 aliyun-python-sdk-kms-2.16.5 antlr4-python3-runtime-4.9.3 audioread-3.0.1 bitarray-3.6.0 bitstring-4.3.1 coloredlogs-15.0.1 crcmod-1.7 datasets-3.2.0 distance-0.1.3 editdistance-0.8.1 espnet_tts_frontend-0.0.3 funasr-1.2.6 g2p-2.1.0 g2p-en-2.1.0 greenlet-3.2.3 grpcio-1.74.0 h5py-3.14.0 hdbscan-0.8.40 humanfriendly-10.0 hydra-core-1.3.2 hyper-connections-0.2.1 hyperpyyaml-1.2.2 inflect-7.0.0 jaconv-0.4.0 jamo-0.4.1 jieba-0.42.1 jmespath-0.10.0 kaldiio-2.18.1 kantts-0.1.0 kwsbp-0.1.0 lazy-loader-0.4 librosa-0.10.1 local-attention-1.11.2 markdown-3.8.2 mir-eval-0.8.2 modelscope-1.24.1 ms-funcodec-0.2.0 msgpack-1.1.1 munkres-1.1.4 nltk-3.9.1 omegaconf-2.3.0 oss2-2.19.1 panphon-0.20.0 phaseaug-1.0.1 pickleshare-0.7.5 pooch-1.8.2 ptflops-0.7.4 py-sound-connect-0.1.0 pycryptodome-3.23.0 pynndescent-0.5.13 pypinyin-0.44.0 pytorch-wavelets-1.3.0 pytorch-wpe-0.0.1 rotary-embedding-torch-0.8.9 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 sentencepiece-0.2.0 setuptools-69.5.1 sox-1.5.0 soxr-0.5.0.post1 speechbrain-1.0.3 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorboardX-2.6.4 text-unidecode-1.3 thop-0.1.1.post2209072238 torch-complex-0.4.4 typeguard-2.13.3 umap-learn-0.5.9.post2 unicodecsv-0.14.1 unidecode-1.4.0 werkzeug-3.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip3 install modelscope[audio]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1f42fc-5913-491b-8d66-80ae405fe198",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 20:26:47,534 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "2025-08-01 20:26:48,655 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/luany/.cache/modelscope/hub/models/iic/speech_paraformer_asr_nat-zh-cn-8k-common-vocab8358-tensorflow1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 20:26:48,782 - modelscope - INFO - initiate model from /home/luany/.cache/modelscope/hub/models/iic/speech_paraformer_asr_nat-zh-cn-8k-common-vocab8358-tensorflow1\n",
      "2025-08-01 20:26:48,783 - modelscope - INFO - initiate model from location /home/luany/.cache/modelscope/hub/models/iic/speech_paraformer_asr_nat-zh-cn-8k-common-vocab8358-tensorflow1.\n",
      "2025-08-01 20:26:48,784 - modelscope - INFO - initialize model from /home/luany/.cache/modelscope/hub/models/iic/speech_paraformer_asr_nat-zh-cn-8k-common-vocab8358-tensorflow1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 20:26:52,163 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-08-01 20:26:52,164 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-08-01 20:26:52,165 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/home/luany/.cache/modelscope/hub/models/iic/speech_paraformer_asr_nat-zh-cn-8k-common-vocab8358-tensorflow1'}. trying to build by task and model information.\n",
      "2025-08-01 20:26:52,165 - modelscope - WARNING - No preprocessor key ('funasr', 'auto-speech-recognition') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "  0%|\u001b[34m                                                                                                                                                                                        \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.76 GiB. GPU 0 has a total capacity of 5.68 GiB of which 270.44 MiB is free. Including non-PyTorch memory, this process has 5.35 GiB memory in use. Of the allocated memory 5.20 GiB is allocated by PyTorch, and 14.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# rec_result = inference_pipeline('/home/luany/桌面/mp4/output.wav')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# 在FP16环境下执行\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast():\n\u001b[0;32m---> 22\u001b[0m     rec_result \u001b[38;5;241m=\u001b[39m \u001b[43minference_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/luany/桌面/test.m4a\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 必须设为1\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 分段处理\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(rec_result)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# # 初始化 SenseVoice 管道\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# # 模型会自动下载到 ~/.cache/modelscope/\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# sense_voice_pipeline = pipeline(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# 保存为文本文件\u001b[39;00m\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/pipelines/audio/funasr_pipeline.py:73\u001b[0m, in \u001b[0;36mFunASRPipeline.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    Decoding the input audios\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m        a list of dictionary of result.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/models/base/base_model.py:35\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/modelscope/models/audio/funasr/model.py:61\u001b[0m, in \u001b[0;36mGenericFunASR.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     58\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"preload model and return the info of the model\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/auto/auto_model.py:303\u001b[0m, in \u001b[0;36mAutoModel.generate\u001b[0;34m(self, input, input_len, **cfg)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, input_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg):\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvad_model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_with_vad(\u001b[38;5;28minput\u001b[39m, input_len\u001b[38;5;241m=\u001b[39minput_len, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcfg)\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/auto/auto_model.py:345\u001b[0m, in \u001b[0;36mAutoModel.inference\u001b[0;34m(self, input, input_len, model, kwargs, key, **cfg)\u001b[0m\n\u001b[1;32m    343\u001b[0m time1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 345\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    347\u001b[0m         results \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/models/paraformer/model.py:500\u001b[0m, in \u001b[0;36mParaformer.inference\u001b[0;34m(self, data_in, data_lengths, key, tokenizer, frontend, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    499\u001b[0m     speech \u001b[38;5;241m=\u001b[39m speech\u001b[38;5;241m.\u001b[39mhalf()\n\u001b[0;32m--> 500\u001b[0m encoder_out, encoder_out_lens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeech\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeech_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_out, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    502\u001b[0m     encoder_out \u001b[38;5;241m=\u001b[39m encoder_out[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/models/paraformer/model.py:262\u001b[0m, in \u001b[0;36mParaformer.encode\u001b[0;34m(self, speech, speech_lengths, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m         speech, speech_lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(speech, speech_lengths)\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Forward encoder\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m encoder_out, encoder_out_lens, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspeech\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeech_lengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_out, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    264\u001b[0m     encoder_out \u001b[38;5;241m=\u001b[39m encoder_out[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/models/sanm/encoder.py:400\u001b[0m, in \u001b[0;36mSANMEncoder.forward\u001b[0;34m(self, xs_pad, ilens, prev_states, ctc)\u001b[0m\n\u001b[1;32m    397\u001b[0m     xs_pad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed(xs_pad)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# xs_pad = self.dropout(xs_pad)\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m encoder_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoders0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m xs_pad, masks \u001b[38;5;241m=\u001b[39m encoder_outs[\u001b[38;5;241m0\u001b[39m], encoder_outs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    402\u001b[0m intermediate_outs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/models/transformer/utils/repeat.py:32\u001b[0m, in \u001b[0;36mMultiSequential.forward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mor\u001b[39;00m (_probs[idx] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_drop_rate):\n\u001b[0;32m---> 32\u001b[0m         args \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/models/sanm/encoder.py:131\u001b[0m, in \u001b[0;36mEncoderLayerSANM.forward\u001b[0;34m(self, x, mask, cache, mask_shfit_chunk, mask_att_chunk_encoder)\u001b[0m\n\u001b[1;32m    121\u001b[0m         x \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m stoch_layer_coeff \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\n\u001b[1;32m    122\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    123\u001b[0m                 x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m             )\n\u001b[1;32m    128\u001b[0m         )\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m         x \u001b[38;5;241m=\u001b[39m stoch_layer_coeff \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\n\u001b[0;32m--> 131\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m                \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmask_shfit_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_shfit_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmask_att_chunk_encoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_att_chunk_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m         )\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_before:\n\u001b[1;32m    139\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/models/sanm/attention.py:310\u001b[0m, in \u001b[0;36mMultiHeadedAttentionSANM.forward\u001b[0;34m(self, x, mask, mask_shfit_chunk, mask_att_chunk_encoder)\u001b[0m\n\u001b[1;32m    308\u001b[0m q_h \u001b[38;5;241m=\u001b[39m q_h \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md_k \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    309\u001b[0m scores \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(q_h, k_h\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 310\u001b[0m att_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_h\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask_att_chunk_encoder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m att_outs \u001b[38;5;241m+\u001b[39m fsmn_memory\n",
      "File \u001b[0;32m~/jnote/lib/python3.10/site-packages/funasr/models/sanm/attention.py:278\u001b[0m, in \u001b[0;36mMultiHeadedAttentionSANM.forward_attention\u001b[0;34m(self, value, scores, mask, mask_att_chunk_encoder)\u001b[0m\n\u001b[1;32m    274\u001b[0m     min_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     )  \u001b[38;5;66;03m# float(numpy.finfo(torch.tensor(0, dtype=scores.dtype).numpy().dtype).min)\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     scores \u001b[38;5;241m=\u001b[39m scores\u001b[38;5;241m.\u001b[39mmasked_fill(mask, min_value)\n\u001b[0;32m--> 278\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmasked_fill(\n\u001b[1;32m    279\u001b[0m         mask, \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    280\u001b[0m     )  \u001b[38;5;66;03m# (batch, head, time1, time2)\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    282\u001b[0m     attn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (batch, head, time1, time2)\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.76 GiB. GPU 0 has a total capacity of 5.68 GiB of which 270.44 MiB is free. Including non-PyTorch memory, this process has 5.35 GiB memory in use. Of the allocated memory 5.20 GiB is allocated by PyTorch, and 14.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "\n",
    "# 关键优化设置（SenseVoice 同样适用）\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "inference_pipeline = pipeline(\n",
    "    task=Tasks.auto_speech_recognition,\n",
    "    model='iic/speech_paraformer_asr_nat-zh-cn-8k-common-vocab8358-tensorflow1',\n",
    "    model_revision=\"master\",\n",
    "    model_kwargs={\"fp16\": True},  # 强制FP16模式,\n",
    "    device=\"cuda:0\")\n",
    "\n",
    "# rec_result = inference_pipeline('/home/luany/桌面/mp4/output.wav')\n",
    "\n",
    "# 在FP16环境下执行\n",
    "with torch.cuda.amp.autocast():\n",
    "    rec_result = inference_pipeline(\n",
    "        '/home/luany/桌面/test.m4a',\n",
    "        batch_size=1,  # 必须设为1\n",
    "        chunk_size=[10, 5]  # 分段处理\n",
    "    )\n",
    "\n",
    "print(rec_result)\n",
    "\n",
    "# # 初始化 SenseVoice 管道\n",
    "# # 模型会自动下载到 ~/.cache/modelscope/\n",
    "# sense_voice_pipeline = pipeline(\n",
    "#     task=Tasks.auto_speech_recognition,\n",
    "#     model=\"iic/SenseVoiceSmall\",  # 官方推荐中文模型\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# )\n",
    "\n",
    "# # 转录音频\n",
    "# result = sense_voice_pipeline(\n",
    "#     input=\"/home/luany/桌面/mp4/output.wav\",\n",
    "#     language=\"zh\",  # 显式指定中文\n",
    "#     batch_size=1,    # 减少显存占用\n",
    "#     output_timestamps=False  # 关闭时间戳节省显存\n",
    "# )\n",
    "\n",
    "# 输出结果（SenseVoice返回格式与Whisper不同）\n",
    "# transcribed_text = rec_result[\"text\"]  # SenseVoice的文本在\"text\"字段\n",
    "# print(transcribed_text)\n",
    "\n",
    "# 保存为文本文件\n",
    "with open(\"/home/luany/桌面/mp4/transcription.txt\", \"w\") as f:\n",
    "    f.write(rec_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43cc55c6-fc0b-4927-9489-92b09d0f3b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 19:20:38,918 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/luany/.cache/modelscope/hub/models/iic/SenseVoiceSmall\n",
      "Loading remote code failed: ./model.py, No module named 'model'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-31 19:20:41,995 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /home/luany/.cache/modelscope/hub/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.066: 100%|\u001b[34m█████████████████████████████\u001b[0m| 1/1 [00:03<00:00,  3.15s/it]\u001b[0m\n",
      "  0%|\u001b[31m                                                     \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "  0%|\u001b[34m                                                    \u001b[0m| 0/11 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m███████████████████████████████████████████\u001b[0m| 11/11 [00:00<00:00, 61.72it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.012', 'forward': '0.178', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.009: 100%|\u001b[34m███████████████████████████\u001b[0m| 11/11 [00:00<00:00, 59.70it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/6 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 6/6 [00:00<00:00, 40.55it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.022', 'forward': '0.148', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 6/6 [00:00<00:00, 38.64it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/5 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 5/5 [00:00<00:00, 31.57it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.024', 'forward': '0.158', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 5/5 [00:00<00:00, 30.21it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/5 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 5/5 [00:00<00:00, 28.48it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.026', 'forward': '0.176', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.002: 100%|\u001b[34m█████████████████████████████\u001b[0m| 5/5 [00:00<00:00, 27.32it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/4 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 4/4 [00:00<00:00, 18.71it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.029', 'forward': '0.214', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 4/4 [00:00<00:00, 17.85it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 3/3 [00:00<00:00, 14.78it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.032', 'forward': '0.203', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 3/3 [00:00<00:00, 14.20it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/3 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 3/3 [00:00<00:00, 13.21it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.034', 'forward': '0.227', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 3/3 [00:00<00:00, 12.73it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.37it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.025', 'forward': '0.162', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.77it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.91it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.030', 'forward': '0.168', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.43it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.29it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.025', 'forward': '0.163', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.77it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.26it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.023', 'forward': '0.163', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.72it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.18it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.025', 'forward': '0.164', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.67it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.26it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.025', 'forward': '0.163', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.61it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.76it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.029', 'forward': '0.170', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.23it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.35it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.023', 'forward': '0.162', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.77it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.30it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.023', 'forward': '0.163', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.70it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.28it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.035', 'forward': '0.177', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 10.79it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.45it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.033', 'forward': '0.175', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 10.92it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.10it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.024', 'forward': '0.165', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.53it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.21it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.025', 'forward': '0.164', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.66it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                     \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.012', 'forward': '0.085', 'batch_size'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████\u001b[0m| 1/1 [00:00<00:00, 10.81it/s]\u001b[0m\u001b[A\n",
      "rtf_avg: 0.003, time_speech:  1247.655, time_escape: 3.806: 100%|\u001b[31m█\u001b[0m| 1/1 [00:04<0\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".大家好，今天是2025年的3月12号星期三啊，讲这个卢群元这个凯恩斯啊就业利息和货币通用第六讲啊。第六讲呢讲的是通论里边第三章，这就都正常进正常进入了他呢是从里面挑着讲，他这个顺序也不是按正常通用的顺序去讲，明白吗？然后他会把他其中呢像这个是第三章，他下一讲应该把十3章十4章呢凑在一起了啊，这是按照这样讲的，就是说呃他有他的这么一个顺序方便以理解，因为说实话像资本。和通论这种东西不好理解，大不同你自己去读的话，你你很能读不到什么，好不好？那我们这种讲法时，你才能真的理解他为什么这么写它的目的是什么。好吧，那我们来看啊，拿日本举例啊。1985年广场协议的核心点就是要求呢日元的这个升息啊。那这章呢主要讲的呢就是这个有效需求啊。我们来看看啊日元升值。日元升值之后呢，涉及到呢什么呢？就是说呢货币的问题，就是货币升值了啊，那日元升级升值之后导致日本货币总总量呢膨胀。就什么概念呢？就是日元的数量并没有增加。它不是说多发了货币。但是呢由于升值了之后呢，日元的购买力增增强了，就升值之后，日元购买力增强，怪得到迅速膨胀，所以货币总量的这种膨胀。是这个导致总需求的增长，明白吗？就是说我买用的能能够更多，那么我的需求就更多啊，那么就成为了一个就是说货币总量的膨胀呢，是总需求增长中的一个根本性的一个原因。好，在这的时候你要理解它这是通过货币升值导致的，我还可以通过多发货币导致。明白吗？那么回来下一章可能就会讲到了，就是说那么我们如果呃时不时的多发一点货币的话，实际上就能够提高了总需求提高了经济。发展。所以就为什么你看基本上经济学家都保障每一年有2%的通货膨胀，你明白这意思吧？就也就在这儿，然后在然后在呢每一年呢根据你的这个GDP呢再相应的开始呢多发一点货币啊。好，那么当然总需求呢和有效需求呢是两码事啊，总需求攀升之后，大量的货币呢变成了两个东西。一个呢就是投资性的需求。因为挣了钱嘛，是投资，另外一个就消费性的需求，挣了钱呢去消费啊，那投资性需求呢导致日本的房地产和股市呢就起飞啊，整个就疯掉，封掉之后呢，由于货币量太大了，日本放不下，就进行大规模的海外投资，主要呢进入美国，就当时呢就是觉得呢把东京房地产都卖掉，就可以把整个美国都买下来了。还记得吧？到美国买什么。大厦什么时啊？那这个呢实质上本质是一个资本外逃的过程，你能明白吗？啊，同时呢又有大量的消费性需求。消费性需求提高之后呢，日本本国呢无法满足，我满足了之后呢，就要从国外的进口。当时的日本比如说买LV包啊，当时LV会专门给日本出日本特供的一些包的这个款式啊，颜色啊，都会有啊。你现在你包括你像艾比艾比呃，我记得去年的时候就给日本出了一个专门的一个日本配色的一个。😊呃，蓝宝石的这个艾比的那个就那个呃呃呃双飞轮啊，就很好看那个表，这也是日本特供，对不对？那么就都会有。因为当时日本挣钱嘛，买的东西多啊，那这些奢侈品呢就专门给他提供很多东西。那日本国内呢无法无法满足的这种需求。那么就需要外部性的消费需求。那么外部性的投资呢和这种消费需求呢会导致什么，导致日本大量资本外溢。Yeah.明白吗？因为人家艾比也好，人家LV来了，等家挣了钱之后，人家要要拿走的，明明吗？那这个钱实际上就都出去了。那么到1991年呢，经济泡沫破灭之后，日本进入大萧条。由于国产协议的约束呢，日元又不能够迅速贬回到了300。那么这个日本呢就必须要消化了资产泡沫，消化了这个杠杆。那这个过程呢呢用了差不多30年的时间啊，这是一次呢，就是说洗劫。那中国呢也类似出现过这种问题。中国2012年到2018年。投资了3万亿美元，有3万亿美元，从中国呢离离开了中国到海外去了啊，形成了这种外部性的投资需求，到外部去投资啊，有的买球队，有买什么AMC电影院，是不是还是AMD电影院想不起来了，反正这个还买什么那个什么纽约买了个那那那谁呀，吴吴晓辉在纽约买了个酒店啊，挺有名的。华尔道夫酒店什么的，反正是吧？反正就形成了这种外部性的呢消费需求啊，就是说有外部性的投资外部性的消费啊，外部性的意思就。这种投资和消费不能构成中国本国的就业那？对中国本国没有什么好处，帮美国来提高就业来了啊，那内部的有效需求呢相对缩显，内部的供给呢就被呢逐层的消灭。日本1991年之后呢，资本的大规模外逃，相当于一部分的工业特别是外半导体为代表的工业呢大体就要流失了。因为你的资本不在了，资本不在难以支撑。那么你的产业呢就流失了啊，那凯恩斯的就业呢就不是指单纯的总业这个就业的呢就是总数量，明道吗？就像。刚刚我们讲到货币的这个总量，货币总量呢不仅仅是发行货币，还有货币的升值或贬值，知吧？货币升值了它的总量也在提高，贬值了总量也在减少。那么就业呢也在这块，它指的是总劳动，总劳动是什么呢？就是说你的劳动得到的这个相应的报酬吧，那你拿到的你我们有劳动，对吧？得到这个工资，那日本总劳动呢是减少了的，可能就业人数还多了，大家工作时间更长了。但是你得到的这个报酬呢更低了，所以总劳动呢实际上是减少了，就是日元贬值之后导致。呢降低啊，仍然贬值了，你当然还挣到这些钱，但是牛买力降低了，所以总劳动呢反而在降低啊，总劳动降低呢总总收入降低，总需求也降低啊。那百度百科或者维基百科上呢，关于有效需求定义的是错的，那有效需求呢真的是不好定义。所以呢先给你一个简单的定义，让你理解。就比如说先画一个圆，这个圆呢是一个总需求，是一个圆，我这边再画一个圆，两个圆呢交叠在一起，中间有一个重复部分，对不对？好，那这个左边这圆的的总需求，右边这个圆叫总供给。😊然后两个人呢交叉了之后呢，就有交集这个交集的部分啊，那么就认为呢就是有效需求了。啊，就交集的部分就是就有效需求。就是说呢我的总需求，总供给啊，我的需求和供给都需要的那一部分就是那另外一部分呢就就不算啊，那么交集的部分呢是这个有效需求，但是并不是全部的有效需求。为什么呢？因为有效需求还有外部性的。😊有内部性的有效需求是什么呢？有一些比如说。比如说你像中国我们生产了一些包啊，一些衣服啊，Teach恤卖到美国来了，好不好？那这个需求是外部需求，是美国对中国的需求，我们出口了。那但是这个呢的确他干什么呢？他增加了中国的就业。明白吗？增加了中国就济业，增加了中国的经济增长，这是好事儿。所以这个呢也是有效需求。但是这个有效需求是外部的，不是你中国内部的，还有有效供给呢，也是有内部的，有外部的，就说我的一些供给，这个供给能不能提高我的这个我国家的就业呀，提高我国家的这个经济增长啊，有对不对？但是你这个供给是给谁的，也是给美国的，那这就是外部的了，明白吗？那我们刚刚说的是你国内的总需求和总供给。但呢还有外部的那外部的也都加进去了，那这个也算是有效需求。那但是外部的有效需求啊，那日元贬值的意思就是说总货币呢在在收缩。那总货币收缩就会导致呢总需求收缩，知道吗？就是说这个供给和需求总是相等的，就是所谓的萨一定律啊，那总需求收缩的同时呢，总供给呢就收缩。总供给和总需求呢，就是按理来讲应该是恒定的啊，就是按照萨一定律。但是这个来讲呢，它是它有个问题，什么问题呢？就是说市场会自动完成总供给与总需求的平衡。也为他们有一阵不平衡了。你说他横动的，那为什么要说这样一旦不平衡之后呢，市场就会去调节，导致他们的平衡啊，就是导致他们永远都有这个平衡。至于呢当然呢就是平衡过程当中，那可能是非常惨烈的啊，比如像1929年70%的人失业，可能会导致很多人露宿街头，很多人饥饿和饥饥病，很多人的人均寿命呢迅速下降。但是呢在这些呢坐在这个西阿拜塔里的经经济学家们就认为这个没事就应该的，这是一个自然现象啊，那么市场。场调节呢就是这样残酷的，没办法，就涉立达尔本主义。然后当政府和财政部和央行拿这个理论来制定政策的时候，就会导致老百姓巨大的痛苦，并且有可能给国家带来灾难性的后果啊，我们讲赤德迷斯时就提到过，凯尔顿就说。😊Yeah.凯尔顿说呢，就是说在过去来讲，这个自由经济学的理论就认为就是说呃适量的这个失业率是好的。就到一定程度之后，如果失业率现到一个点的话，我们就不能再刺激经济了。因为再次激下有可脑是通货膨胀。所以呢就是说他老是保持着美国有那么个几百万人失业。你知道吗？他认为呢这样是好的，对经济是良性发展的。但凯尔顿呢认为呢就是说但是为了让美国经济联性发展，总有几百万人在失业。嗯你这是对的吗？他认为这个其实是不对的，你不应该你不应该这么做，等于你用了几百万人，他们的痛苦来让你社会的良性发展。那这就变成社会大尔本主义了，知道吗？就是说。高居庙堂之上的这些经济学家，这些经济政策制定者们不会为这几百万人去去去去制定。按理说你再多搞搞经济，再搞得好一点，这五六百万人也能够去就业。但是他觉得呢不行了，不用再搞了啊，就是这么残酷，他们活该实业，没办法，你懂吗？但是这个呢理论上是是不对的，这个不道德啊，好。。我看啊，那么有效需求的定义是什么呢？是能够有效提升本国就业水平和工资水平的这种的需求啊，所以这个有效需求就的理解的定义，它是就很多很多几个，反正你就自己去理解，好吧，那这个能用排他法吗？也不行，所以这个非常的麻烦，就能不能倒过来说，比如说你不能够说就是说你比如说那如果不能够提升本国的就业水平，不能够有效提高本国工资水平的需求，难道就一定要算上无效需求吗？你怎么你也不能这么说，比如说那我真的就买了LV包，这LV包不是在中国制造的，在海外制造的，或者买了艾比的手表，或者你瑞士手表，瑞士手表都是在瑞士制造的，不是在中国制造的那你买了这个之后，是不是这就是一定是无效需求呢？你也很难说，所以这个定义他他就你就只能自己去理解。好吧，那无效需求呢就会有一个问题。呃，就是说你不能倒过来说啊，就是说不能够有效提升本国工资水平的需求，这不一定就是都是无效需求。经济学的一些理论呢是原则不是原理。原理呢才能够呢去反正，而原则呢很多事没法没法反证，你就理解就得了。所以无效需求里边来讲呢，还有一点，比如举个例子，举当都是几个极端例子，再举个更极端一点例子，就是什么毒品啊，那如果我国家知道毒品。那这是不是一个无效需求，这是个无效需求，对不对？但是呢你要看啊，在1840年的时候，英国人后来主要呢是美国人，他们拿毒品这种无效需求，就鸦片跟大英帝国呢进行了与英国和美国的贸易平衡，贸易再平衡。到时我我白银进不来，进来出不去嘛？我拿我拿鸦片卖给鸦片之后岛致他能出得去。那你说这是个无效需求吧，但是对于。😊。嗯，大清来讲是个无效需求，但对于英国和美国来讲还是不错的呢，对不对？他也生产了这这个产品，拿这个产品到最后呢的确呢让他能达到他一个贸易平衡，对不对？那他们不说嘛，说这个也也也也到了中国亚太战争的时候，中国不是芬泰尼嘛，但是这芬泰尼你很难说说楚中国又不是在黑市上卖。他当药物卖的。那你加拿大和墨西哥那可能没有处理好，对吧？不当然这个也就是一个借口，这个是借口，其实串股上来之后呢，加拿墨西哥现在早都没有人进来了，也没有毒品进来了，加关税。一个理由而已啊，但不管怎么着吧，你就你就理解这个情况啊。好吧，那么就是个无效需求呢，比如说什什么过渡的房屋需求啊，那一个人你买了3000平米的房子，或者你买了30套房子，就叫过渡需求。过度需求就会导致呢过度的供给啊，因为你大家都买30套房子，大家就对那地产方就多开多开发，多建房子啊，那这个呢就是无效需求的。无效需求导致的供给呢。在经济学理论上实际上呢是一个跨期的问题，这跨的是时间，就是时间轴的问题，在特定的时间能够表达为呢有效供给，就是你现在比如买了30套房子，过几年房产崩了，你就开始卖卖到你亏了，但是对社会可能还有好处，导致那天买不起房，买不起房子能买得起房子来了，知道吗？所以呢。😊就是说这个经济学呢，它最后呢就你定要明白一点，最终的经济学应该是一个5维空间。明白吗？就是正常的，你认为首先它应该是个三维的，对不对？就是说比如说国家政策啊，外部政策啊，它应该是个是是设个三维空间，对不对？但是事实实上呢，它不是经济学首先这样，先加一个第四维，第四维，你知叫什么吗？第四维就是时间。😊时间不一样是不一样，你看这个就很明显。由于时间不一样之后，你的无效需求，最后可能在一些特定时间表达为有效供给了，明白吗？表达为有效需求，表达为。有效供给了。通过比如说你今年造的房子，今年不是十年之后可能是了，你明白这意思吧？那么这就是一个时间问题，还有你的利息，你的房租啊，因为它就你看就业利息和货币嘛，对不对？那你的利息利息我存天进去之后，那你利息是按年按年走的，对不对？那这个也是要交由时间了，明白吗？那这就在时间上，那为什么说五维呢？好，三维到四维，就是说打开时间是是个四维，这个好理解，对不对？五维，什么是空间？😊空间不一样。就最简单的就是说在美国或在中国能一样吗？啊，你知道产品卖到美国去，还是在中国消化能一样吗？是美国的需求在拉动你的经济发展，还是你自己国内的内需，在拉动你的发展发展，这是不一样的，明白吗？就是两个大循环到底是内循环还是外循环，这个是不一样的，这是这是空间的问题，时间上不一样，空间上不一样，那么你加上时间就是四维了，再加上一个空间呢，那就变成五维了，明道吗？所以经济学它实际上是个5维空间的一个东西，你才能够理解啊，好。😊。大家看啊，那么提升他国就业水平呢，也不能叫呢这个无效需求。但是呢也不想到这样来呢这个定义啊，所以你不能说一个中国人买了个苹果手机就一定是无效需求，不能呢这么去定义。因为这买了苹中国呢也有点好处，但是好处还是美国多，对不对？还有像你买阿根廷的牛肉，那是不是就是无效需求呢，也不能这么说，你不能将这个定义呢变成国家的经济政策，因为 Trump普呢他就是这么想问题，这 Trump普想问些角度，对不对？买中国货都买美国货，对不对？美国优先，对不对？因为所以呢。就搞贸易战，那有效需求和有效供给的理解呢是非常复杂的。所以为什么说百度百科和北机百上也都是错的。但是他讲了半天能不能讲清楚呢，你也只能意会了，就没法言传。你说了几个定义。最后呢你会发现都有一点点缺陷，你画图出来也有一点点缺陷，都有一点点缺陷。还有你像这个国外的这个需求和供给。你比如说比如说啊我们买了阿根廷的牛肉啊，对于我们来讲可能是一个变成一个无效需求了。但是我买了阿根廷牛肉挣了阿根廷的钱，阿根廷换人民币。拿人民币呢再跟他呢，比如说或者说我们先拿人民币跟阿根廷呢买了这个牛肉，然后他有人民币，然后他再拿人民币呢跟华为呢买一些的5G设备的东西做行一个交换，对不对？那我们虽然买了牛肉，但他买了华为的东西，那最后是不是有效需求呢他倒倒了其实还是你明白了吗？他其实还他还是个有效需求，所以这东西呢就他不好理解，但是呢你就去理解的吧，就是说也不是说外部外部需求就一定是无效的，有一些人有效的，明白吧？好吧。😊那分类里呢有效需求呢分为国内有效需求，国外有效需求，供给呢也可以分为呢国内呢和国外，那你就明白这意思了。然后有的时候呢国内和外呢进行交换。交换之后呢，其实对你发展呢也有帮助，好吧。呃，那么凯恩斯呢将这理论呢就概述为呢几个命题啊，就那么几个谜题。第一个增加有效需求的一个原则啊，什么原则呢？就是应该有序的增加货币供应。就刚刚我说了，就是你的货币总量在提高的同时必然导致什么，导致你的总需求呢在这个提高，明白吗？那这经济发展就有好处的，所以呢就是说是就是说要有序的啊正常的一点点的在增加呢这个货币供应。所以为什么我说比特币和黄金是我们不可能回到基本。🤧对了，比特币也不可能，因为它它是有数的，你没法增加，你不增加经济就不发展了就变成通缩了，明白吗？😊当然呢，你在增加总货币供应的时候呢，必须务必要减少的资本外溢啊，来呢这个我喝口水啊，渴死我。.也有什么意思呢？就是说你总货币如果增加了，同时你如果不能够减少资本外溢的话，像日本一样，你总货币增加了，他们都拿去美国买房子了。那你这个资本等于就跑出去了，就走私了，对吧？所以呢有序增加的意思就是就是总货币的增加，是经济增长的原动力，这个呢是必须的，也是需要的。这没问题。但是一定要警觉，就是增加总货币是在不资本外逃前提之下，如果资本外逃，比如说中国2012年到2018年，中国3万亿美元外逃，对不对？导致什么呢？导致中国总货币的增加还不如外逃的多。那么你这时你增加货币总量就不会增加有效的这个需求了，明白这意思吧？那么第二个增加内部有效需求，要拉动的内部有效的供给啊，就是说我内部。要要要扩大内需，就说来就是扩大内需，扩大内需，就可以提供的提高呢我内部的供给，这样就可以提高就业，对吧？那不能够增加内部有效需求来拉动他外部有效供给。就什么意思？就是说我内部有有有需求，想买苹果手机，想买劳力士，对不对？想买这个LV对不对？然后最后呢都是都是外国构造的，那我得拉动国外去了，我最后没得到任何好处啊，那第三个呢，增加外部有效需求来消化自己内部的有效供给。什么意思呢？比如说。😊到中国到外边去投资。哎，我借给你人民币，我帮你呢修这个高铁，帮你修码头，帮你修飞机场。但是你要给我买水泥，你你懂我意思吗？就是我到外部去进行了一些呢帮助一些投资业经济发展。然后呢，但它实际上呢在消化我内部的有效供给啊，可能我水泥太太多了，刚才太多了，对不对？对来了嘛，对不对？这是一个。第4个要减少内部的无效需求啊，这这无效需求就是说不能这么说，但是呢就是说少买到苹果手机都往花要先其实。这么个意思，这话是不能这么说的，那川普也这个想法，这就是不对的。而你这么一想的话呢，会导致了贸易战，对不对？所以话呢是不能这么说的。但所但是呢那你要怎么理解呢？你要你就要又能又能理解，又不能说懂我意思吗？所以这些东西呢它其实它有个蹊跷劲啊那第五条增加呢向外提供的呢一切供给增加呢外部供给啊，当然了，这里边来讲呢，就应不能不能够包含呢什么鸦片啊、军火呀，你懂我意思，就什么意思呢？就是说我尽量呢。出口挣外汇明白吗？就增加呢向外提供的一切供给，增加外国供给，我向外面去供给去去卖东西，然后挣挣美元挣外汇回来，对不对？但是呢就是最好呢不要向外卖的什么芬泰尼卖鸦片，卖军火这些因就这不好嘛，对吧？你说你看这美国有外卖卖军火嘛，不缺德吗？你卖军火那让人打仗嘛，农民不杀人嘛，对不对？😊I.那么第六条呢，保持本地的价值载量水平，避免了这通货膨胀啊。如果通货膨胀太厉害了，你货币贬值太厉害的话呢，你的货币总量也在下降。那你在你如果货币下降的特别快，你即使再增加的话，你增加数量的话，你的货币总量也没有增加，这对经济发展就不利了。好吧，第七条呢，一些战略储备啊，那说呢不应该在外面买东西，在国内买东西。但是比如说我们买黄金呢，我要买石油呢，买一些战略储备呢，对买稀土呢，那这些呢是还是要需要的这没办法。这战略储备方面呢。该该花钱还得花，这没辙，对不对？第八条呢，精兵简政，尽可能压缩呢基于政府行政事业的无效需求。就是说经济不好的时候，政府花点钱拉动下这个需求是可以的。但是呢经济好的时候呢，你不能玩命的这么做，不能最后呢都靠政府。你像这个我就说这拜登包威尔，拜登这4年，对不对？整个社会总需求40%多，将近将近一半了，都是美国政府创造的都政府创造的，那你这这这行吗，对不对？而你政府钱从哪来，政府不光欠债了嘛，就就。变成一个无底洞了，不能这么搞。好吧，那这就是他的这个有效需求呢，就8个命题啊，大家就都理解了。反正这个有效需求这个呢这第第第第六讲呢主要讲有有效需求，在有效需求呢真的是不好理解，我们只能说呢从方方面面呢尽量的去让你尝试去理解，还呢有效需求，无效需求到底是什么，这无效需求也不能一竿子打死，但你要明白的就是都是说不清楚的，但是呢你都要能你还都要明白好不好？我觉得呢。本来是说不清的东西，但是让我言简意赅的一说，你就明白。开个玩笑啊。好吧，那这期就到这里吧，谢谢大家。😊\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "\n",
    "model_dir = \"iic/SenseVoiceSmall\"\n",
    "\n",
    "model = AutoModel(\n",
    "    model=model_dir,\n",
    "    trust_remote_code=True,\n",
    "    remote_code=\"./model.py\",  \n",
    "    vad_model=\"fsmn-vad\",\n",
    "    vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=f\"/home/luany/桌面/mp4/output.wav\",\n",
    "    cache={},\n",
    "    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2c852c-d445-47e2-9793-81b736d03772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n",
      "Downloading Model from https://www.modelscope.cn to directory: /home/luany/.cache/modelscope/hub/models/iic/SenseVoiceSmall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 23:52:05,327 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading remote code failed: ./model.py, No module named 'model'\n",
      "Downloading Model from https://www.modelscope.cn to directory: /home/luany/.cache/modelscope/hub/models/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 23:52:08,297 - modelscope - WARNING - Using branch: master as version is unstable, use with caution\n",
      "rtf_avg: 0.030: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 1/1 [00:01<00:00,  1.55s/it]\u001b[0m\n",
      "  0%|\u001b[31m                                                                 \u001b[0m| 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/4 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 4/4 [00:00<00:00, 12.16it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.024', 'forward': '0.329', 'batch_size': '4', 'rtf'\u001b[A\n",
      "rtf_avg: 0.006: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 4/4 [00:00<00:00, 11.83it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.95it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.029', 'forward': '0.167', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.48it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.91it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.030', 'forward': '0.168', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.42it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.00it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.028', 'forward': '0.167', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.52it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.07it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.027', 'forward': '0.166', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.56it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.16it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.027', 'forward': '0.164', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.63it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.19it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.025', 'forward': '0.164', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.55it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.58it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.031', 'forward': '0.173', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.13it/s]\u001b[0m\u001b[A\n",
      "\n",
      "  0%|\u001b[34m                                                                 \u001b[0m| 0/2 [00:00<?, ?it/s]\u001b[0m\u001b[A\n",
      "100%|\u001b[34m█████████████████████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 12.05it/s]\u001b[0m\u001b[A\n",
      "{'load_data': '0.000', 'extract_feat': '0.029', 'forward': '0.166', 'batch_size': '2', 'rtf'\u001b[A\n",
      "rtf_avg: 0.003: 100%|\u001b[34m█████████████████████████████████████████\u001b[0m| 2/2 [00:00<00:00, 11.58it/s]\u001b[0m\u001b[A\n",
      "rtf_avg: 0.003, time_speech:  531.876, time_escape: 1.768: 100%|\u001b[31m█\u001b[0m| 1/1 [00:02<00:00,  2.33s/\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎼hello大家好，我是老高。财购自由团的内容，咱们已经做了正好一年了啊，我们是去年518开始了，所以大概过去了一年，不知道大家的成绩怎么样。我这两天呢一直在想一个事情啊，就是我分享的这些经验是否真的有效。特别是我讲短影片的部分。因为我记得我第三个影片就说过啊，如果我要从现在开始做的话，一定先从短影片开始。整个影片里我讲了一堆短影片的好处啊。后来有观众问一些相关的问题的话，我一都推荐大家做短影片。但说实话啊，我在短影片方面是没有任何实际经验的。因为我一直都在做长影片，我也不止一次的讲过，长影片和短影片的受众呢不是一伙人。既然不是一伙人的话，我这套东西真的对于短影片的受众有用吗？还有一个问题就是我的这些经验直到今天是否依然有效的问题啊。因为我们刚刚讲过就推过了一些算法，其实在一直变化的。而我的这些经验现在是否有效呢，也是一个未知数是吧？所以呢我在前两天做了一个决定，就是想要自己来做一下短影片试试看啊。我总跟大家说，你一个事情你不了解的话，不知道怎么做，或者是就我给你讲的东西你都听不懂的话，你最好去。🎼你试过之后，你就会发现它可能和你想象的完全不一样。有一些难点呢，有些技巧肯定是通过肉眼看不到的，必须自己亲自去做一下，才能体会到。那么我也是只有自己在这方面有一些经验，才能更好的把这些实用的东西反馈给大家，顺便验证一下自己的想法，自己的判断，以防止给大家传达了一些过时的甚至错误的信息就不好了。所以呢我在5月下旬的时候建立一个全新的频道啊。那么为了完全屏蔽我自身对这个频道的影响。那我就全新申请了一个邮箱啊，又用这个全新的邮箱呢注册了一个youtube账号。然后呢，为了。进一步排除干扰啊，我还去买了一台新的电脑。我平时剪辑和上传影片都一直用一个苹果的笔记本电脑，这一台呢就肯定不能用了。然后我就去苹果呢买了一台小的苹果mini啊，就写了台式机，就用它呢专门来做新的影片啊，因为做短视频啊，mini就可以了。整个新频道的运营呢也在那个新的电脑上来做啊。这样的话，从我这边呢所有的客观影响基本上就可以排除掉。接下来呢还要屏蔽各位的影响，所以我不会告诉大家这个频道是什么频道，它的地址啊，它的相关信息都不会说的我会给大家。🎼展示一部分后台，但是可能和这个频道本身产生关联的信息呢，是不会告诉各位的。因为只要公开的话，就会或多或少的产生一些影响啊，实验的意义就没有。就像医学上的双盲测试一样，要想知道一个方法是否有效的话，必须保证被实验者和实验者都忙的状态才行。所有的影响都排除掉才行。这样呢准备好一切之后呢，我在5月下旬就开始一个新的频道。这个频道已经有了啊，我已经开始做了。那我本来打算呢是先做一个月看看，体会一下短视频的难度，在什么地方啊，然后咱们来调整一下接下来要讲的。内容结果发生了个意外情况啊，就是当我上传到第五个视频的时候，我基本上是一天一个啊，上传到第五个的时候呢啊突然爆了啊，就是定位数额播放量都暴涨，而且爆的有点出乎意料啊。一个是爆的特别快嘛，不到一周就爆了，还有个出乎意料呢，就是爆的量啊，这个爆的影片第一天的播放量就明显比其他高一点啊，前四个影片基本播放量是4000到7000。那么这第五个爆的影片呢，第一天上去呢就是这个播放量的10位就达到了4万。第二天这个影片的播放量就达到了24万。第三天呢达到了。🎼500万，第四天呢达到了4000万，第五天呢就过亿了啊，第六天呢1.8亿。第七天呢还没完呢啊，我拍这个影片的时候，他正在第七天，现在已经2亿多。也就是说不到一周大概2亿多播放啊，那么这个影片带来订阅数呢也超过18万。我想这个速度一定会减缓的，极限可能会落在三四亿左右。对了，我刚才说的这些播放呢都是实际播放呢，就是后台看到的播放量。前台播放量可能会更高。那么这个影片暴涨这一段时间啊，我也坚持在上传其他的影片。那么后来上传的影片呢就没有爆的感觉了。但这些影片。也都在这个暴涨影片的带动之下，播放量都不低啊，一般第一天的播放量都能达到几十万啊，但最终落在什么地方就不一定啊，有的停留在几十万。那么有的呢就可以落到几百万。我目前看到是这样，那么之前上传的4个影片呢也会被带动上涨，但是被带动的力度呢感觉就没有之后的影片那么大。那么这个突发情况呢确实打乱了我的一些计划啊。然后我本来想测试的一些东西没法测了。但是他也间接证明了我讲的很多东西应该是没有问题的，尤其对于运营频道的思路和对youtube的理解这个部分，我觉得是绝对。🎼没问题的完全是按照我跟大家说的一步一步来做的啊，保持每天更新，做自己想做的内容，去想象观众想要的东西，把这个东西给他们就可以了。当然我知道这个事情绝对不止这几句话这么简单啊，如果就这么几句话的话，我们也不会做一年，但思路绝对是没有错的啊，我也肯定做不到我认知之外的事情啊。只要能做的就说明这个事情在我认知之内，我觉得唯一一个比较特别的地方，也有可能是造成这个影片播放量如此巨大的一个重要原因的。这个我也讲过了，就是我这次做的呢不是中文的内容，我不止一次说过，他也不上。中文圈其实不大，做中文内容是比较吃亏的，尤其是做短视频啊，短视频啊年性比较低，所以他非常吃观众基数，粘性高的东西有点观众基础就可以。比如像财经类了，B圈类了，他就靠那么一点点忠实的观众就可以财富自由了。但是如果年性低的话，圈子又小，那起步就比较吃亏。想要快速起步的话，就要做大圈子的东西。比如说唱歌跳舞搞笑音乐游戏之类。总之，你在任何短视频平台上一刷一堆的东西都是大圈子的东西。所以首先你要搞清楚你是哪个圈子了。你要想做跳舞的影片的话，那就做短的。🎼不要做长的，搞笑的就做短的，但是讲一些很专业的东西，就做长的，不是说做短的不行。只要你想留人，就一定要做长的。因为只有长的才有粘性。那些谁看都无所谓的影片的话，你就做短的。因为短的效率高，所以整体来说，我去年一年讲的绝大部分东西呢是没有问题的。只要照做不说一周就能解锁盈利吧啊，三个月肯定是没有问题的。只是我比较担心大家是否真的理解我说的话的意思。确实很多事情用语言是很难表达的。所以我才说一定要去试嘛，很多东西啊，我告诉你怎么做，你自己不做的话，你是体会。那么我为了理解大家的处境，我也要去试嘛，都一样的。所以真的很希望大家不是在那里听，要真的去做啊。我看到我们很多财富自由团的观众，去看他们的频道，频道更新的速度真的是太慢了啊，然后呢还有留言问说为什么我们频道增长这么慢，你做的太慢了呀。你如果能保证每一期都报的话，做的慢是可以的。你什么都保证不了的情况下，你应该更加勤奋一点，更加勤奋，并不是说你只要做的多，你就一定能成功。是在你做的过程中，你不断的试错的过程中，你大概你就知道有什么问题了。试是为了试错。🎼而不是为了说堆积视频，只有你试出了一个成功的样本之后，接下来就复制这个样本就可以了。所有的成功路径都是这样的。其实大家肯定听说过很多成功人士的一些经历啊，他们在早期的时候都非常痛苦。有那么一段黑暗时期，那段黑暗时期是什么？就是试错的时期嘛，所以各位想要成功也是一样，你都需要有一个黑暗的时期。那么你可能会反问说为什么我做第五个视频就可以报。因为我有十几年做长视频的经验，而且这个经验是成功的经验，你可能也做了十几年，但你这个经验不成功的话，你再继续复制。你不成功的经验是没有意义的。所以你一定要要成功一次，而你要想成功，你就得不停的试，直到试到成功为止，你要相信只要做了立刻就会有感觉啊。就像骑自行车一样，你看别人骑的都非常的顺畅，你不止意亲自坐上去的时候，你是不知道骑自行车是什么感觉。你光看也是不会学会骑自行车的。所以想到就立刻去做，做了之后就立刻会有感觉。不管这个感觉是痛苦也好，还是幸运也好，，我可能确实是幸运了。但是如果是运气更好。因为如果是运气的话，你才有机会。如果这个事情全部是实力。🎼只有我才能做到的话，你就没有机会啊啊，所以我宁愿相信这是问运气。但是是不是运气都是做了之后才知道做的多了人运气自然多一些，所以勇敢去做啊。当然通过反思呢，我也发现了，我以前讲的东西呢也有有问题的地方。比如说啊我之前有说过，我说新频道大家要有一定的耐心，要让tu认识到你的频道是安全的，才可能去推荐你。现在来看的话，全新的频道应该是没问题的。现在Tbe似乎对全新的频道也是无防备的啊，这是一个很好的信号。所以大家如果有这么想法，就可以用新频道去尝试。不会因。😊你是个新频道就打压你，折磨你是吧？有很多观众问过这种问题，就说我这个频道很新，他会不会打压我会不会折磨我。现在看来不会不会让你一定做满三个月才会给你机会，可时间已经没关系了。在这个部分呢，我觉得我的想法是有点保守了。至少我以前做的时候，我会有这个感觉啊，我觉得需需要一个认识你的过程。很有可能以前是这样的，但是现在呢因为设了一个盈利的那个条件，以前没有盈利条件，所以他对频道相对来说是比较谨慎的。现在有盈利条件，他可以用这个条件来卡你。他对你频道的。🎼初期发展就不需要有那么多的限制，这是一个特别好的事情啊。那么整体来说呢，我觉得有问题的。可主要就是这个地方。其他关于思路啊，关于具体操作的部分应该都没什么问题。好，那么今天呢咱们就先讲到这儿啊，说这么久也没有告诉大家，我这个频道是什么频道，做了什么内容啊，很抱歉啊，暂时还不能告诉大家，因为这个频道我还要用来测试，它成立时间实在是有点太短了。我还有很多想做的事情还没来得及做啊，以后会慢慢做。当然这个频道后续测试中，如果发现什么有趣的事情啊，也会分享给大家，希望大家能够期待啊。好，那么今天呢就先到这里。我们下期再见，拜拜。🎼 は。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "\n",
    "model_dir = \"iic/SenseVoiceSmall\"\n",
    "\n",
    "\n",
    "model = AutoModel(\n",
    "    model=model_dir,\n",
    "    trust_remote_code=True,\n",
    "    remote_code=\"./model.py\",  \n",
    "    vad_model=\"fsmn-vad\",\n",
    "    vad_kwargs={\"max_single_segment_time\": 30000},\n",
    "    device=\"cuda:0\",\n",
    ")\n",
    "\n",
    "# en\n",
    "res = model.generate(\n",
    "    input=f\"/home/luany/桌面/laogao/mp4/27_一週年特別影片，我秘密建了一個新頻道.m4a\",\n",
    "    cache={},\n",
    "    language=\"auto\",  # \"zn\", \"en\", \"yue\", \"ja\", \"ko\", \"nospeech\"\n",
    "    use_itn=True,\n",
    "    batch_size_s=60,\n",
    "    merge_vad=True,  #\n",
    "    merge_length_s=15,\n",
    ")\n",
    "text = rich_transcription_postprocess(res[0][\"text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bd2939-8384-467c-b435-b8cfaf3c22ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5729a-57bc-4485-b884-207ec83bcdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
